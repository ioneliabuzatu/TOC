{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "coastal-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import scanpy as sc\n",
    "from dask import dataframe as dd\n",
    "import dask\n",
    "import pickle\n",
    "import numpy\n",
    "import h5py\n",
    "import tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "premier-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_count_matrix_filename = './Tran_RGC_scRNA/unzipped/GSE137398_ONCRGCs_control_count_mat.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "artistic-acrylic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-prisoner",
   "metadata": {},
   "source": [
    "### Read large csv with pandas no chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "duplicate-factor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with pandas without chunks:  171.90068125724792 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pandas_df = pd.read_csv(control_count_matrix_filename)\n",
    "end = time.time()\n",
    "print(\"Read csv with pandas without chunks: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "precise-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df_to_np = pandas_df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-ballet",
   "metadata": {},
   "source": [
    "### Read large csv with npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "supported-direction",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"npy.npy\", pandas_df_to_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "educated-scheme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read with npy: 15.772084951400757 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "np_df = np.load(\"npy.npy\", allow_pickle=True)\n",
    "print(f\"Read with npy: {time.time()-start} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-numbers",
   "metadata": {},
   "source": [
    "### Read large csv with pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dressed-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pandas_df_to_np, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fifth-audit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read with pickle: 16.956642389297485 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "with open(\"test.pkl\", \"rb\") as f:\n",
    "        pickle_df = pickle.load(f)\n",
    "print(f\"Read with pickle: {time.time()-start} sec\")       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-budapest",
   "metadata": {},
   "source": [
    "### Read large csv with h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"hdf5.h5\", \"w\")\n",
    "f.create_dataset(\"data\", data=pandas_df_to_np)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "f = h5py.File(\"out.h5\", \"r\")\n",
    "out = f[\"data\"][()]\n",
    "f.close()\n",
    "print(f\"Read with h5: {time.time()-start} sec\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-obligation",
   "metadata": {},
   "source": [
    "### Read large csv with scanpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fabulous-strength",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with scanpy: 56.38237380981445 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "scanpy_df = sc.read_csv(control_count_matrix_filename, first_column_names=True)\n",
    "print(f\"Read csv with scanpy: {time.time()- start} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "afraid-wellington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40790, 17887)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanpy_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-trial",
   "metadata": {},
   "source": [
    "### Read large csv with pandas chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "level-silly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with chunks:  0.007316112518310547 sec\n",
      "Concat with pandas chunk 166.26809334754944 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pandas_chunk_df = pd.read_csv(control_count_matrix_filename,chunksize=1000000)\n",
    "end = time.time()\n",
    "print(\"Read csv with chunks: \",(end-start),\"sec\")\n",
    "pd_concat_df = pd.concat(pandas_chunk_df)\n",
    "print(f\"Concat with pandas chunk {time.time()-start} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-exposure",
   "metadata": {},
   "source": [
    "### Read large csv with dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "apparent-samoa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with dask:  58.971813440322876 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "dask_df = dd.read_csv(control_count_matrix_filename, sample=1000000)\n",
    "end = time.time()\n",
    "print(\"Read csv with dask: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "specific-project",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of dask dataframe 148.48653936386108 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "dask_df.head()\n",
    "print(f\"Head of dask dataframe {time.time()-start} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_df_compute = dask_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(dask_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "future",
   "language": "python",
   "name": "future"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
